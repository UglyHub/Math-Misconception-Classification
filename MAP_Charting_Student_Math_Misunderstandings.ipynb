{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a53203c011c48d5bb10a43bf1aa413b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9d4192b072648ef9cf2a93bcbbcd442",
              "IPY_MODEL_81a3cc869a154e7fae51ad126ef3fbeb",
              "IPY_MODEL_42b39d07747d4ec9b9a90b1c00254862"
            ],
            "layout": "IPY_MODEL_f6dc6e66451c42b38b38db38718737d9"
          }
        },
        "a9d4192b072648ef9cf2a93bcbbcd442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89b156f5114b462a8b706d5647c62835",
            "placeholder": "​",
            "style": "IPY_MODEL_5a83950ef46a410ea218456c217a9b33",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "81a3cc869a154e7fae51ad126ef3fbeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c158085a751b47a8a84fafc3d9359bfa",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7b5beb2f0254d578a59d05849a39bad",
            "value": 52
          }
        },
        "42b39d07747d4ec9b9a90b1c00254862": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bf198057956402bb9fb4a4f404f5031",
            "placeholder": "​",
            "style": "IPY_MODEL_15ed36473ad14008a75098b3ee0ccd38",
            "value": " 52.0/52.0 [00:00&lt;00:00, 4.71kB/s]"
          }
        },
        "f6dc6e66451c42b38b38db38718737d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b156f5114b462a8b706d5647c62835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a83950ef46a410ea218456c217a9b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c158085a751b47a8a84fafc3d9359bfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7b5beb2f0254d578a59d05849a39bad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bf198057956402bb9fb4a4f404f5031": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15ed36473ad14008a75098b3ee0ccd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3466f13b20f441a589aef40974bdad21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7609d3e3a1404b1782d6f12fc4e9d54d",
              "IPY_MODEL_a6e1aa15346645a9bec93888b60de6fa",
              "IPY_MODEL_88565671f927403b849d8ec1d87c9404"
            ],
            "layout": "IPY_MODEL_c550f667e89543e7ac428dc9f35a50c0"
          }
        },
        "7609d3e3a1404b1782d6f12fc4e9d54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e687829d083d4cc19e1b90e13c669ddf",
            "placeholder": "​",
            "style": "IPY_MODEL_fd19b6571f4b4be1a71e84057098ba03",
            "value": "config.json: 100%"
          }
        },
        "a6e1aa15346645a9bec93888b60de6fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcc9d98713d14f27859c42e48e3ff4bf",
            "max": 578,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3ce04675a814264aa6f0a9df7c3ae21",
            "value": 578
          }
        },
        "88565671f927403b849d8ec1d87c9404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1685db46904c44459587aa5355d91bb9",
            "placeholder": "​",
            "style": "IPY_MODEL_95e3d679a8b346d9bdbd68eeb4c0042b",
            "value": " 578/578 [00:00&lt;00:00, 65.9kB/s]"
          }
        },
        "c550f667e89543e7ac428dc9f35a50c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e687829d083d4cc19e1b90e13c669ddf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd19b6571f4b4be1a71e84057098ba03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcc9d98713d14f27859c42e48e3ff4bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3ce04675a814264aa6f0a9df7c3ae21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1685db46904c44459587aa5355d91bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e3d679a8b346d9bdbd68eeb4c0042b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "668cbded27f24ea5abb69119998f8f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c43d9323e4db46529b5d11ddb0d6894c",
              "IPY_MODEL_3620e42f0ec84d4d833666aaea517008",
              "IPY_MODEL_affa9699ece649ff8a2b17187b8741b9"
            ],
            "layout": "IPY_MODEL_bc0a79e2a46641adac74ed77b7308721"
          }
        },
        "c43d9323e4db46529b5d11ddb0d6894c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8df4d4986f3e43ff9e9f2b44411e09bc",
            "placeholder": "​",
            "style": "IPY_MODEL_2bcdddaa64d14b62a146e61506a24cf5",
            "value": "spm.model: 100%"
          }
        },
        "3620e42f0ec84d4d833666aaea517008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_427c9716296a443abeb60a61dad4bba8",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e443bc00eb804b92b966a5ea77f4058c",
            "value": 2464616
          }
        },
        "affa9699ece649ff8a2b17187b8741b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7e9e9d469504727b95912d9a4cf9a61",
            "placeholder": "​",
            "style": "IPY_MODEL_84fcec2f4b70440c85054aae0404db3e",
            "value": " 2.46M/2.46M [00:01&lt;00:00, 52.5kB/s]"
          }
        },
        "bc0a79e2a46641adac74ed77b7308721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8df4d4986f3e43ff9e9f2b44411e09bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bcdddaa64d14b62a146e61506a24cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "427c9716296a443abeb60a61dad4bba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e443bc00eb804b92b966a5ea77f4058c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7e9e9d469504727b95912d9a4cf9a61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84fcec2f4b70440c85054aae0404db3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ad5zAg9Ui6yT",
        "outputId": "70a54990-2664-4101-f8c4-d570057efd32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch pandas numpy sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 0: Initial Setup and Library Installation ---\n",
        "# This part ensures you have all necessary libraries in your Colab environment.\n",
        "\n",
        "# If you encounter issues with transformers version or dependencies,\n",
        "# you might need to restart the runtime after installation.\n",
        "# For example, after installing accelerate, you might get a prompt to restart.\n",
        "!pip install -qqq transformers datasets evaluate accelerate scikit-learn pandas numpy torch\n",
        "!pip install -qqq sentencepiece # DeBERTa-v3 uses SentencePiece tokenizer\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import average_precision_score\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import logging as hf_logging\n",
        "import gc\n",
        "\n",
        "# Suppress Hugging Face warnings for cleaner output\n",
        "hf_logging.set_verbosity_error()\n",
        "\n",
        "print(\"Libraries installed and imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Clear GPU cache if any to free up VRAM\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"CUDA cache cleared.\")"
      ],
      "metadata": {
        "id": "u1g1JQaEvgkS",
        "outputId": "21b2da93-f92d-47df-85a9-fa946d2283f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hLibraries installed and imported successfully!\n",
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "CUDA device name: Tesla T4\n",
            "Using device: cuda\n",
            "CUDA cache cleared.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 1: Load and Inspect Data ---\n",
        "\n",
        "# Load the datasets\n",
        "try:\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    test_df = pd.read_csv('test.csv')\n",
        "    sample_submission_df = pd.read_csv('sample_submission.csv')\n",
        "    print(\"train.csv, test.csv, and sample_submission.csv loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Ensure train.csv, test.csv, and sample_submission.csv are uploaded to your Colab environment.\")\n",
        "    print(\"You can drag and drop them into the 'Files' section on the left sidebar.\")\n",
        "    # Exit or handle error appropriately\n",
        "    exit() # Exiting for now if files are not found\n",
        "\n",
        "print(\"\\n--- Train Data Info ---\")\n",
        "train_df.info()\n",
        "print(\"\\n--- Test Data Info ---\")\n",
        "test_df.info()\n",
        "\n",
        "print(\"\\n--- First 5 rows of Train Data ---\")\n",
        "print(train_df.head())\n",
        "print(\"\\n--- First 5 rows of Test Data ---\")\n",
        "print(test_df.head())\n",
        "\n",
        "print(\"\\n--- Unique Categories and Misconceptions in Train Data ---\")\n",
        "print(\"Categories:\", train_df['Category'].unique())\n",
        "print(\"Misconceptions:\", train_df['Misconception'].unique())"
      ],
      "metadata": {
        "id": "jfHftP6rvoPj",
        "outputId": "b4a31f5f-acc3-450a-fa33-f1365ca3c997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.csv, test.csv, and sample_submission.csv loaded successfully!\n",
            "\n",
            "--- Train Data Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 36696 entries, 0 to 36695\n",
            "Data columns (total 7 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   row_id              36696 non-null  int64 \n",
            " 1   QuestionId          36696 non-null  int64 \n",
            " 2   QuestionText        36696 non-null  object\n",
            " 3   MC_Answer           36696 non-null  object\n",
            " 4   StudentExplanation  36696 non-null  object\n",
            " 5   Category            36696 non-null  object\n",
            " 6   Misconception       9860 non-null   object\n",
            "dtypes: int64(2), object(5)\n",
            "memory usage: 2.0+ MB\n",
            "\n",
            "--- Test Data Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3 entries, 0 to 2\n",
            "Data columns (total 5 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   row_id              3 non-null      int64 \n",
            " 1   QuestionId          3 non-null      int64 \n",
            " 2   QuestionText        3 non-null      object\n",
            " 3   MC_Answer           3 non-null      object\n",
            " 4   StudentExplanation  3 non-null      object\n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 252.0+ bytes\n",
            "\n",
            "--- First 5 rows of Train Data ---\n",
            "   row_id  QuestionId                                       QuestionText  \\\n",
            "0       0       31772  What fraction of the shape is not shaded? Give...   \n",
            "1       1       31772  What fraction of the shape is not shaded? Give...   \n",
            "2       2       31772  What fraction of the shape is not shaded? Give...   \n",
            "3       3       31772  What fraction of the shape is not shaded? Give...   \n",
            "4       4       31772  What fraction of the shape is not shaded? Give...   \n",
            "\n",
            "           MC_Answer                                 StudentExplanation  \\\n",
            "0  \\( \\frac{1}{3} \\)                  0ne third is equal to tree nineth   \n",
            "1  \\( \\frac{1}{3} \\)  1 / 3 because 6 over 9 is 2 thirds and 1 third...   \n",
            "2  \\( \\frac{1}{3} \\)  1 3rd is half of 3 6th, so it is simplee to un...   \n",
            "3  \\( \\frac{1}{3} \\)        1 goes into everything and 3 goes into nine   \n",
            "4  \\( \\frac{1}{3} \\)                    1 out of every 3 isn't coloured   \n",
            "\n",
            "       Category Misconception  \n",
            "0  True_Correct           NaN  \n",
            "1  True_Correct           NaN  \n",
            "2  True_Neither           NaN  \n",
            "3  True_Neither           NaN  \n",
            "4  True_Correct           NaN  \n",
            "\n",
            "--- First 5 rows of Test Data ---\n",
            "   row_id  QuestionId                                       QuestionText  \\\n",
            "0   36696       31772  What fraction of the shape is not shaded? Give...   \n",
            "1   36697       31772  What fraction of the shape is not shaded? Give...   \n",
            "2   36698       32835                      Which number is the greatest?   \n",
            "\n",
            "           MC_Answer                                 StudentExplanation  \n",
            "0  \\( \\frac{1}{3} \\)  I think that 1/3 is the answer, as it's the si...  \n",
            "1  \\( \\frac{3}{6} \\)  i think this answer is because 3 triangles are...  \n",
            "2          \\( 6.2 \\)     because the 2 makes it higher than the others.  \n",
            "\n",
            "--- Unique Categories and Misconceptions in Train Data ---\n",
            "Categories: ['True_Correct' 'True_Neither' 'True_Misconception' 'False_Neither'\n",
            " 'False_Misconception' 'False_Correct']\n",
            "Misconceptions: [nan 'Incomplete' 'WNB' 'SwapDividend' 'Mult' 'FlipChange' 'Irrelevant'\n",
            " 'Wrong_Fraction' 'Additive' 'Not_variable' 'Adding_terms'\n",
            " 'Inverse_operation' 'Inversion' 'Duplication' 'Wrong_Operation'\n",
            " 'Whole_numbers_larger' 'Longer_is_bigger' 'Ignores_zeroes'\n",
            " 'Shorter_is_bigger' 'Wrong_fraction' 'Adding_across'\n",
            " 'Denominator-only_change' 'Incorrect_equivalent_fraction_addition'\n",
            " 'Division' 'Subtraction' 'Unknowable' 'Definition' 'Interior' 'Positive'\n",
            " 'Tacking' 'Wrong_term' 'Firstterm' 'Base_rate' 'Multiplying_by_4'\n",
            " 'Certainty' 'Scale']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Prepare Target Labels (Corrected) ---\n",
        "\n",
        "# Ensure Category and Misconception are strings and handle potential NaNs\n",
        "train_df['Category'] = train_df['Category'].fillna('').astype(str)\n",
        "train_df['Misconception'] = train_df['Misconception'].fillna('').astype(str)\n",
        "\n",
        "# Create combined Category:Misconception labels for training data\n",
        "# Now, all values in 'Category' and 'Misconception' are guaranteed to be strings.\n",
        "train_df['Target'] = train_df['Category'] + ':' + train_df['Misconception']\n",
        "\n",
        "# Get all unique possible Category:Misconception labels from the training data\n",
        "all_possible_labels = sorted(train_df['Target'].unique().tolist())\n",
        "print(f\"\\nTotal unique target labels: {len(all_possible_labels)}\")\n",
        "# print(\"All possible labels:\", all_possible_labels) # Uncomment to see all labels\n",
        "\n",
        "# Map labels to integers and vice versa\n",
        "label_to_id = {label: i for i, label in enumerate(all_possible_labels)}\n",
        "id_to_label = {i: label for i, label in enumerate(all_possible_labels)}\n",
        "\n",
        "# Convert target labels in train_df to one-hot encoded format\n",
        "# MultiLabelBinarizer is perfect for this, even if initially we have single labels\n",
        "# It prepares for a multi-label classification setup, which is necessary for MAP@3\n",
        "mlb = MultiLabelBinarizer(classes=all_possible_labels)\n",
        "train_labels_one_hot = mlb.fit_transform(train_df['Target'].apply(lambda x: [x]))\n",
        "\n",
        "print(f\"\\nShape of one-hot encoded labels: {train_labels_one_hot.shape}\")\n",
        "# print(\"Example one-hot label for first row:\", train_labels_one_hot[0])\n",
        "\n",
        "# --- Preprocessing Function and Dataset Class (No change, including for your reference) ---\n",
        "\n",
        "def preprocess_text(question_text, mc_answer, student_explanation):\n",
        "    \"\"\"\n",
        "    Combines all text inputs into a single string for the transformer model.\n",
        "    Handles potential NaN values by converting them to empty strings.\n",
        "    \"\"\"\n",
        "    # Ensure all inputs are strings, replace NaN with empty string\n",
        "    q_text = str(question_text) if pd.notna(question_text) else \"\"\n",
        "    mc_ans = str(mc_answer) if pd.notna(mc_answer) else \"\"\n",
        "    s_expl = str(student_explanation) if pd.notna(student_explanation) else \"\"\n",
        "\n",
        "    # Using a clear separator like [SEP] is good practice for transformers\n",
        "    # It helps the model distinguish between different parts of the input.\n",
        "    return f\"Question: {q_text} | Answer: {mc_ans} | Explanation: {s_expl}\"\n",
        "\n",
        "# Apply preprocessing to both train and test data\n",
        "train_df['ProcessedText'] = train_df.apply(\n",
        "    lambda row: preprocess_text(row['QuestionText'], row['MC_Answer'], row['StudentExplanation']),\n",
        "    axis=1\n",
        ")\n",
        "test_df['ProcessedText'] = test_df.apply(\n",
        "    lambda row: preprocess_text(row['QuestionText'], row['MC_Answer'], row['StudentExplanation']),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(\"\\n--- Example of Processed Text (Train Data) ---\")\n",
        "print(train_df['ProcessedText'].iloc[0])\n",
        "print(\"\\n--- Example of Processed Text (Test Data) ---\")\n",
        "print(test_df['ProcessedText'].iloc[0])\n",
        "\n",
        "class MathMisconceptionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom PyTorch Dataset for handling text tokenization and label preparation.\n",
        "    \"\"\"\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels # Labels are already one-hot encoded\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        text = str(self.texts[item])\n",
        "        labels = self.labels[item] # Get the pre-processed one-hot labels\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(labels, dtype=torch.float) # Labels as float for BCEWithLogitsLoss\n",
        "        }"
      ],
      "metadata": {
        "id": "8RbpSeLyvo2x",
        "outputId": "f42749f3-9924-4c23-ab30-f98711e9e190",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total unique target labels: 65\n",
            "\n",
            "Shape of one-hot encoded labels: (36696, 65)\n",
            "\n",
            "--- Example of Processed Text (Train Data) ---\n",
            "Question: What fraction of the shape is not shaded? Give your answer in its simplest form. [Image: A triangle split into 9 equal smaller triangles. 6 of them are shaded.] | Answer: \\( \\frac{1}{3} \\) | Explanation: 0ne third is equal to tree nineth\n",
            "\n",
            "--- Example of Processed Text (Test Data) ---\n",
            "Question: What fraction of the shape is not shaded? Give your answer in its simplest form. [Image: A triangle split into 9 equal smaller triangles. 6 of them are shaded.] | Answer: \\( \\frac{1}{3} \\) | Explanation: I think that 1/3 is the answer, as it's the simplest form of 3/9.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 3: Model Selection, Tokenizer and Data Preparation ---\n",
        "\n",
        "MODEL_NAME = 'microsoft/deberta-v3-small' # A powerful small model\n",
        "MAX_LEN = 256 # Max sequence length for tokenizer. Adjust based on text length and GPU memory.\n",
        "              # 256 is a good starting point for 13GB GPU RAM. Can try 512 if memory allows.\n",
        "BATCH_SIZE = 16 # Adjust based on GPU memory. 16 is a safe start, try 32 if possible.\n",
        "NUM_EPOCHS = 3 # Number of training epochs. Start with 3, increase if not overfitting.\n",
        "\n",
        "# Load Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "print(f\"\\nTokenizer loaded: {MODEL_NAME}\")\n",
        "\n",
        "# Create Datasets\n",
        "train_dataset = MathMisconceptionDataset(\n",
        "    texts=train_df['ProcessedText'].tolist(),\n",
        "    labels=train_labels_one_hot,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=MAX_LEN\n",
        ")\n",
        "\n",
        "# For test dataset, labels are not available. We'll use a dummy array or None.\n",
        "# Here we use a dummy array of zeros, as the model will predict logits anyway.\n",
        "test_dummy_labels = np.zeros((len(test_df), len(all_possible_labels)))\n",
        "test_dataset = MathMisconceptionDataset(\n",
        "    texts=test_df['ProcessedText'].tolist(),\n",
        "    labels=test_dummy_labels, # Dummy labels for inference\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=MAX_LEN\n",
        ")\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "\n",
        "# --- Step 4: Define Evaluation Metric (MAP@3) ---\n",
        "\n",
        "def calculate_map_at_3(y_true_one_hot, y_pred_probs, all_labels):\n",
        "    \"\"\"\n",
        "    Calculates Mean Average Precision @ 3 (MAP@3).\n",
        "    y_true_one_hot: True labels (one-hot encoded).\n",
        "    y_pred_probs: Predicted probabilities (output from model).\n",
        "    all_labels: List of all possible Category:Misconception labels.\n",
        "    \"\"\"\n",
        "    map_scores = []\n",
        "    # Loop through each sample\n",
        "    for i in range(y_true_one_hot.shape[0]):\n",
        "        true_labels_idx = np.where(y_true_one_hot[i] == 1)[0]\n",
        "        # Map true label indices back to actual label strings (there's only one true label per row in our data)\n",
        "        true_label_str = [all_labels[idx] for idx in true_labels_idx]\n",
        "\n",
        "        # Get predicted probabilities for this sample and sort them\n",
        "        pred_probs_for_sample = y_pred_probs[i]\n",
        "        # Get indices that would sort pred_probs in descending order\n",
        "        sorted_indices = np.argsort(pred_probs_for_sample)[::-1]\n",
        "\n",
        "        # Get the predicted label strings in order of confidence\n",
        "        predicted_labels_str = [all_labels[idx] for idx in sorted_indices]\n",
        "\n",
        "        # Calculate AP@3 for this sample\n",
        "        precision_at_k = []\n",
        "        num_relevant_found = 0\n",
        "        current_precision_sum = 0\n",
        "        relevant_found_this_sample = set() # To track if a relevant label has been scored\n",
        "\n",
        "        for k in range(min(3, len(predicted_labels_str))):\n",
        "            predicted_label = predicted_labels_str[k]\n",
        "\n",
        "            if predicted_label in true_label_str and predicted_label not in relevant_found_this_sample:\n",
        "                num_relevant_found += 1\n",
        "                relevant_found_this_sample.add(predicted_label)\n",
        "                # Precision at k: (number of relevant items found up to k) / (k+1)\n",
        "                current_precision_sum += num_relevant_found / (k + 1)\n",
        "\n",
        "        if num_relevant_found > 0:\n",
        "            map_scores.append(current_precision_sum / num_relevant_found)\n",
        "        else:\n",
        "            map_scores.append(0.0) # If no relevant items are found in top 3, AP is 0\n",
        "\n",
        "    return np.mean(map_scores)\n",
        "\n",
        "\n",
        "# Custom compute_metrics function for Hugging Face Trainer\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    # Apply sigmoid to logits to get probabilities for multi-label classification\n",
        "    probabilities = torch.sigmoid(torch.from_numpy(logits)).numpy()\n",
        "    map3 = calculate_map_at_3(labels, probabilities, all_possible_labels)\n",
        "    return {\"map@3\": map3}"
      ],
      "metadata": {
        "id": "PZIE1OVWvqcR",
        "outputId": "c053f716-e7eb-41bd-fad9-e57b832e0289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "0a53203c011c48d5bb10a43bf1aa413b",
            "a9d4192b072648ef9cf2a93bcbbcd442",
            "81a3cc869a154e7fae51ad126ef3fbeb",
            "42b39d07747d4ec9b9a90b1c00254862",
            "f6dc6e66451c42b38b38db38718737d9",
            "89b156f5114b462a8b706d5647c62835",
            "5a83950ef46a410ea218456c217a9b33",
            "c158085a751b47a8a84fafc3d9359bfa",
            "e7b5beb2f0254d578a59d05849a39bad",
            "8bf198057956402bb9fb4a4f404f5031",
            "15ed36473ad14008a75098b3ee0ccd38",
            "3466f13b20f441a589aef40974bdad21",
            "7609d3e3a1404b1782d6f12fc4e9d54d",
            "a6e1aa15346645a9bec93888b60de6fa",
            "88565671f927403b849d8ec1d87c9404",
            "c550f667e89543e7ac428dc9f35a50c0",
            "e687829d083d4cc19e1b90e13c669ddf",
            "fd19b6571f4b4be1a71e84057098ba03",
            "bcc9d98713d14f27859c42e48e3ff4bf",
            "e3ce04675a814264aa6f0a9df7c3ae21",
            "1685db46904c44459587aa5355d91bb9",
            "95e3d679a8b346d9bdbd68eeb4c0042b",
            "668cbded27f24ea5abb69119998f8f80",
            "c43d9323e4db46529b5d11ddb0d6894c",
            "3620e42f0ec84d4d833666aaea517008",
            "affa9699ece649ff8a2b17187b8741b9",
            "bc0a79e2a46641adac74ed77b7308721",
            "8df4d4986f3e43ff9e9f2b44411e09bc",
            "2bcdddaa64d14b62a146e61506a24cf5",
            "427c9716296a443abeb60a61dad4bba8",
            "e443bc00eb804b92b966a5ea77f4058c",
            "c7e9e9d469504727b95912d9a4cf9a61",
            "84fcec2f4b70440c85054aae0404db3e"
          ]
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a53203c011c48d5bb10a43bf1aa413b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3466f13b20f441a589aef40974bdad21"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "668cbded27f24ea5abb69119998f8f80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenizer loaded: microsoft/deberta-v3-small\n",
            "Train dataset size: 36696\n",
            "Test dataset size: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5: Model Initialization and Training (Corrected) ---\n",
        "\n",
        "# Load the pre-trained model for sequence classification\n",
        "# num_labels is the total number of unique Category:Misconception combinations\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=len(all_possible_labels),\n",
        "    problem_type=\"multi_label_classification\" # Important for multi-label tasks\n",
        ")\n",
        "model.to(device) # Move model to GPU\n",
        "\n",
        "print(f\"\\nModel loaded: {MODEL_NAME} with {len(all_possible_labels)} output labels.\")\n",
        "\n",
        "# Define Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',                         # Output directory for model checkpoints and logs\n",
        "    num_train_epochs=NUM_EPOCHS,                    # Total number of training epochs\n",
        "    per_device_train_batch_size=BATCH_SIZE,         # Batch size per device during training\n",
        "    per_device_eval_batch_size=BATCH_SIZE,          # Batch size per device during evaluation\n",
        "    warmup_steps=500,                               # Number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,                              # Strength of weight decay\n",
        "    logging_dir='./logs',                           # Directory for storing logs\n",
        "    logging_strategy=\"steps\",                       # Log every n steps\n",
        "    logging_steps=100,                              # Log every 100 steps\n",
        "    # Correction: Use do_eval=False instead of evaluation_strategy=\"no\"\n",
        "    do_eval=False,                                  # Set to False to disable evaluation during training for simplicity\n",
        "                                                    # For real competitions, use True with a validation set\n",
        "    save_strategy=\"epoch\",                          # Save model checkpoint every epoch\n",
        "    load_best_model_at_end=False,                   # We'll save the last checkpoint\n",
        "    fp16=True,                                      # Use mixed precision training for faster training and less memory (if GPU supports)\n",
        "    report_to=\"none\",                               # Disable reporting to services like WandB\n",
        "    learning_rate=2e-5,                             # Standard learning rate for fine-tuning transformers\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    # The compute_metrics function is for evaluation, not directly used in training loss\n",
        "    # The loss function (BCEWithLogitsLoss) is automatically handled by problem_type=\"multi_label_classification\"\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"\\nStarting model training...\")\n",
        "trainer.train()\n",
        "print(\"Model training complete!\")\n",
        "\n",
        "# Clean up memory after training\n",
        "del model\n",
        "del trainer\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "print(\"Memory cleaned up after training.\")"
      ],
      "metadata": {
        "id": "KhLGGyJ5vsip",
        "outputId": "03ce3631-b467-4404-d6c0-78efc8593e3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model loaded: microsoft/deberta-v3-small with 65 output labels.\n",
            "\n",
            "Starting model training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-27-1651670350.py:36: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.6912, 'grad_norm': 0.7639238834381104, 'learning_rate': 3.96e-06, 'epoch': 0.043591979075850044}\n",
            "{'loss': 0.4566, 'grad_norm': 0.8283454775810242, 'learning_rate': 7.960000000000002e-06, 'epoch': 0.08718395815170009}\n",
            "{'loss': 0.1888, 'grad_norm': 0.3975203335285187, 'learning_rate': 1.196e-05, 'epoch': 0.13077593722755013}\n",
            "{'loss': 0.0794, 'grad_norm': 0.2142333686351776, 'learning_rate': 1.5960000000000003e-05, 'epoch': 0.17436791630340018}\n",
            "{'loss': 0.0563, 'grad_norm': 0.28938937187194824, 'learning_rate': 1.9960000000000002e-05, 'epoch': 0.21795989537925023}\n",
            "{'loss': 0.0509, 'grad_norm': 0.20516745746135712, 'learning_rate': 1.9689752428705737e-05, 'epoch': 0.26155187445510025}\n",
            "{'loss': 0.0459, 'grad_norm': 0.1870928257703781, 'learning_rate': 1.9376371043560015e-05, 'epoch': 0.3051438535309503}\n",
            "{'loss': 0.0453, 'grad_norm': 0.17074353992938995, 'learning_rate': 1.9062989658414292e-05, 'epoch': 0.34873583260680036}\n",
            "{'loss': 0.0421, 'grad_norm': 0.21488620340824127, 'learning_rate': 1.874960827326857e-05, 'epoch': 0.3923278116826504}\n",
            "{'loss': 0.0392, 'grad_norm': 0.16250765323638916, 'learning_rate': 1.8436226888122847e-05, 'epoch': 0.43591979075850046}\n",
            "{'loss': 0.0354, 'grad_norm': 0.2514585554599762, 'learning_rate': 1.8122845502977124e-05, 'epoch': 0.47951176983435045}\n",
            "{'loss': 0.0329, 'grad_norm': 0.1621151864528656, 'learning_rate': 1.7809464117831405e-05, 'epoch': 0.5231037489102005}\n",
            "{'loss': 0.0315, 'grad_norm': 0.24556541442871094, 'learning_rate': 1.749608273268568e-05, 'epoch': 0.5666957279860506}\n",
            "{'loss': 0.0277, 'grad_norm': 0.17048902809619904, 'learning_rate': 1.718270134753996e-05, 'epoch': 0.6102877070619006}\n",
            "{'loss': 0.0265, 'grad_norm': 0.20423206686973572, 'learning_rate': 1.6869319962394233e-05, 'epoch': 0.6538796861377506}\n",
            "{'loss': 0.0268, 'grad_norm': 0.13567505776882172, 'learning_rate': 1.6555938577248514e-05, 'epoch': 0.6974716652136007}\n",
            "{'loss': 0.0251, 'grad_norm': 0.10699225962162018, 'learning_rate': 1.624255719210279e-05, 'epoch': 0.7410636442894507}\n",
            "{'loss': 0.0239, 'grad_norm': 0.26222866773605347, 'learning_rate': 1.592917580695707e-05, 'epoch': 0.7846556233653008}\n",
            "{'loss': 0.0227, 'grad_norm': 0.1750018149614334, 'learning_rate': 1.5615794421811346e-05, 'epoch': 0.8282476024411508}\n",
            "{'loss': 0.021, 'grad_norm': 0.16046404838562012, 'learning_rate': 1.5302413036665624e-05, 'epoch': 0.8718395815170009}\n",
            "{'loss': 0.0228, 'grad_norm': 0.15952548384666443, 'learning_rate': 1.4989031651519901e-05, 'epoch': 0.9154315605928509}\n",
            "{'loss': 0.0214, 'grad_norm': 0.16722986102104187, 'learning_rate': 1.467565026637418e-05, 'epoch': 0.9590235396687009}\n",
            "{'loss': 0.0208, 'grad_norm': 0.1418103128671646, 'learning_rate': 1.4362268881228456e-05, 'epoch': 1.002615518744551}\n",
            "{'loss': 0.0189, 'grad_norm': 0.1452965885400772, 'learning_rate': 1.4048887496082735e-05, 'epoch': 1.046207497820401}\n",
            "{'loss': 0.019, 'grad_norm': 0.21352547407150269, 'learning_rate': 1.3735506110937012e-05, 'epoch': 1.0897994768962511}\n",
            "{'loss': 0.019, 'grad_norm': 0.1615372598171234, 'learning_rate': 1.342212472579129e-05, 'epoch': 1.1333914559721012}\n",
            "{'loss': 0.0178, 'grad_norm': 0.1817629635334015, 'learning_rate': 1.3108743340645567e-05, 'epoch': 1.176983435047951}\n",
            "{'loss': 0.0188, 'grad_norm': 0.17646823823451996, 'learning_rate': 1.2795361955499846e-05, 'epoch': 1.2205754141238012}\n",
            "{'loss': 0.0183, 'grad_norm': 0.1440841257572174, 'learning_rate': 1.2481980570354121e-05, 'epoch': 1.2641673931996513}\n",
            "{'loss': 0.0179, 'grad_norm': 0.20481833815574646, 'learning_rate': 1.21685991852084e-05, 'epoch': 1.3077593722755014}\n",
            "{'loss': 0.017, 'grad_norm': 0.1737462431192398, 'learning_rate': 1.1855217800062678e-05, 'epoch': 1.3513513513513513}\n",
            "{'loss': 0.0164, 'grad_norm': 0.16597245633602142, 'learning_rate': 1.1541836414916957e-05, 'epoch': 1.3949433304272014}\n",
            "{'loss': 0.0167, 'grad_norm': 0.1623649299144745, 'learning_rate': 1.1228455029771232e-05, 'epoch': 1.4385353095030515}\n",
            "{'loss': 0.0158, 'grad_norm': 0.13916334509849548, 'learning_rate': 1.0915073644625511e-05, 'epoch': 1.4821272885789014}\n",
            "{'loss': 0.0156, 'grad_norm': 0.12801103293895721, 'learning_rate': 1.0601692259479787e-05, 'epoch': 1.5257192676547515}\n",
            "{'loss': 0.0167, 'grad_norm': 0.22689001262187958, 'learning_rate': 1.0288310874334066e-05, 'epoch': 1.5693112467306016}\n",
            "{'loss': 0.0164, 'grad_norm': 0.15479274094104767, 'learning_rate': 9.974929489188343e-06, 'epoch': 1.6129032258064515}\n",
            "{'loss': 0.0162, 'grad_norm': 0.19674701988697052, 'learning_rate': 9.66154810404262e-06, 'epoch': 1.6564952048823016}\n",
            "{'loss': 0.0155, 'grad_norm': 0.13707855343818665, 'learning_rate': 9.348166718896898e-06, 'epoch': 1.7000871839581517}\n",
            "{'loss': 0.0162, 'grad_norm': 0.1349012404680252, 'learning_rate': 9.034785333751175e-06, 'epoch': 1.7436791630340016}\n",
            "{'loss': 0.0143, 'grad_norm': 0.14351724088191986, 'learning_rate': 8.721403948605453e-06, 'epoch': 1.787271142109852}\n",
            "{'loss': 0.0146, 'grad_norm': 0.09859049320220947, 'learning_rate': 8.408022563459732e-06, 'epoch': 1.8308631211857018}\n",
            "{'loss': 0.0156, 'grad_norm': 0.17124277353286743, 'learning_rate': 8.094641178314009e-06, 'epoch': 1.8744551002615517}\n",
            "{'loss': 0.0151, 'grad_norm': 0.13533583283424377, 'learning_rate': 7.781259793168286e-06, 'epoch': 1.918047079337402}\n",
            "{'loss': 0.0142, 'grad_norm': 0.19293777644634247, 'learning_rate': 7.467878408022564e-06, 'epoch': 1.961639058413252}\n",
            "{'loss': 0.0149, 'grad_norm': 0.2450849562883377, 'learning_rate': 7.154497022876842e-06, 'epoch': 2.005231037489102}\n",
            "{'loss': 0.0136, 'grad_norm': 0.15318036079406738, 'learning_rate': 6.841115637731119e-06, 'epoch': 2.048823016564952}\n",
            "{'loss': 0.0126, 'grad_norm': 0.20021818578243256, 'learning_rate': 6.527734252585397e-06, 'epoch': 2.092414995640802}\n",
            "{'loss': 0.013, 'grad_norm': 0.14356181025505066, 'learning_rate': 6.214352867439675e-06, 'epoch': 2.1360069747166524}\n",
            "{'loss': 0.0138, 'grad_norm': 0.14782026410102844, 'learning_rate': 5.900971482293952e-06, 'epoch': 2.1795989537925022}\n",
            "{'loss': 0.014, 'grad_norm': 0.15326160192489624, 'learning_rate': 5.58759009714823e-06, 'epoch': 2.223190932868352}\n",
            "{'loss': 0.0136, 'grad_norm': 0.16125257313251495, 'learning_rate': 5.274208712002508e-06, 'epoch': 2.2667829119442024}\n",
            "{'loss': 0.014, 'grad_norm': 0.24445393681526184, 'learning_rate': 4.960827326856785e-06, 'epoch': 2.3103748910200523}\n",
            "{'loss': 0.0127, 'grad_norm': 0.21545171737670898, 'learning_rate': 4.647445941711063e-06, 'epoch': 2.353966870095902}\n",
            "{'loss': 0.014, 'grad_norm': 0.2987615466117859, 'learning_rate': 4.334064556565341e-06, 'epoch': 2.3975588491717525}\n",
            "{'loss': 0.0134, 'grad_norm': 0.1349860429763794, 'learning_rate': 4.020683171419618e-06, 'epoch': 2.4411508282476024}\n",
            "{'loss': 0.0137, 'grad_norm': 0.19798529148101807, 'learning_rate': 3.7073017862738957e-06, 'epoch': 2.4847428073234523}\n",
            "{'loss': 0.0128, 'grad_norm': 0.485762357711792, 'learning_rate': 3.3939204011281735e-06, 'epoch': 2.5283347863993026}\n",
            "{'loss': 0.013, 'grad_norm': 0.2001427710056305, 'learning_rate': 3.0805390159824512e-06, 'epoch': 2.5719267654751525}\n",
            "{'loss': 0.0137, 'grad_norm': 0.15942318737506866, 'learning_rate': 2.7671576308367286e-06, 'epoch': 2.615518744551003}\n",
            "{'loss': 0.0136, 'grad_norm': 0.15690219402313232, 'learning_rate': 2.453776245691006e-06, 'epoch': 2.6591107236268527}\n",
            "{'loss': 0.0134, 'grad_norm': 0.21746502816677094, 'learning_rate': 2.1403948605452837e-06, 'epoch': 2.7027027027027026}\n",
            "{'loss': 0.0125, 'grad_norm': 0.1930713802576065, 'learning_rate': 1.8270134753995614e-06, 'epoch': 2.7462946817785525}\n",
            "{'loss': 0.013, 'grad_norm': 0.1190888062119484, 'learning_rate': 1.513632090253839e-06, 'epoch': 2.789886660854403}\n",
            "{'loss': 0.0118, 'grad_norm': 0.10268909484148026, 'learning_rate': 1.2002507051081167e-06, 'epoch': 2.8334786399302527}\n",
            "{'loss': 0.0119, 'grad_norm': 0.1688539981842041, 'learning_rate': 8.868693199623943e-07, 'epoch': 2.877070619006103}\n",
            "{'loss': 0.0125, 'grad_norm': 0.2153937965631485, 'learning_rate': 5.73487934816672e-07, 'epoch': 2.920662598081953}\n",
            "{'loss': 0.0128, 'grad_norm': 0.14698246121406555, 'learning_rate': 2.6010654967094956e-07, 'epoch': 2.964254577157803}\n",
            "{'train_runtime': 1897.1056, 'train_samples_per_second': 58.029, 'train_steps_per_second': 3.628, 'train_loss': 0.03944124486237825, 'epoch': 3.0}\n",
            "Model training complete!\n",
            "Memory cleaned up after training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5: Model Initialization and Training (No changes needed, keeping for context) ---\n",
        "# ... (your existing code for Step 5, just ensure you don't delete model/trainer if you\n",
        "# plan to run Step 6 immediately after without reloading)\n",
        "\n",
        "# For clarity and robustness, I will re-load the model in Step 6.\n",
        "# You can keep the `del model` and `del trainer` at the END of Step 5.\n",
        "# The important part is that we load the model for prediction in Step 6.\n",
        "# If you keep `del model` and `del trainer` in Step 5, make sure you run\n",
        "# Step 5 to completion and then Step 6 in a fresh state (or with reloading as below).\n",
        "\n",
        "# ... (End of your Step 5 code)\n",
        "# Clean up memory after training (Keep these lines if you want to free memory after training phase)\n",
        "# del model\n",
        "# del trainer\n",
        "# gc.collect()\n",
        "# if torch.cuda.is_available():\n",
        "#     torch.cuda.empty_cache()\n",
        "# print(\"Memory cleaned up after training.\")\n",
        "\n",
        "# --- Step 6: Prediction on Test Data (Corrected) ---\n",
        "\n",
        "# Re-load the trained model from the saved checkpoint for prediction\n",
        "# The Trainer saves checkpoints in the `output_dir` specified in TrainingArguments (e.g., './results')\n",
        "# It typically saves a directory like './results/checkpoint-XXXX', where XXXX is the global step.\n",
        "# For simplicity, we'll load the last saved model, which is usually the one at the end of training.\n",
        "# The path to the saved model is usually `output_dir` itself for the final model or `output_dir/checkpoint-XXXX`\n",
        "# After trainer.train(), the model weights are stored in `trainer.model`.\n",
        "\n",
        "# To ensure the model is loaded correctly for prediction even if memory was cleared,\n",
        "# we will re-initialize it.\n",
        "\n",
        "# Load the model again (or load from checkpoint if you prefer to save/load)\n",
        "# The trainer itself doesn't directly save a specific 'best model' path without eval.\n",
        "# The `model` object from Step 5, after `trainer.train()`, holds the fine-tuned weights.\n",
        "# If you *did not* run `del model` and `del trainer` in Step 5, the `model` object is still there.\n",
        "# If you *did* run them, you'd typically load the last saved checkpoint.\n",
        "# Let's assume for robustness that we always re-load.\n",
        "# A simple way to get the last checkpoint if you let `save_strategy=\"epoch\"` is to list the output dir.\n",
        "\n",
        "import os\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
        "\n",
        "# Assuming MODEL_NAME, MAX_LEN, BATCH_SIZE, all_possible_labels, test_dataset, tokenizer are still defined\n",
        "# If you restarted runtime, you might need to re-run imports, model_name, etc.\n",
        "# For this example, let's assume they are globally defined from previous cells.\n",
        "\n",
        "# Re-define TrainingArguments to get the output directory path\n",
        "training_args_for_load = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_eval_batch_size=BATCH_SIZE, # Only need eval batch size for prediction\n",
        "    do_eval=False,\n",
        "    report_to=\"none\",\n",
        "    # Other args are less critical for just loading and predicting\n",
        ")\n",
        "\n",
        "# After training, the best way to ensure you have the trained model is to load\n",
        "# from the latest checkpoint, especially if you deleted `model` and `trainer`\n",
        "# The Trainer saves checkpoints in the format `results/checkpoint-XXXX`.\n",
        "# Let's find the latest checkpoint.\n",
        "\n",
        "model_path = \"./results\" # Default path where `trainer.train()` saves its final model if no checkpointing is explicitly used for final save.\n",
        "# Or, if checkpoints were saved, find the latest one:\n",
        "list_of_dirs = [d for d in os.listdir('./results') if os.path.isdir(os.path.join('./results', d)) and 'checkpoint' in d]\n",
        "if list_of_dirs:\n",
        "    latest_checkpoint = sorted(list_of_dirs, key=lambda x: int(x.split('-')[-1]))[-1]\n",
        "    model_path = os.path.join('./results', latest_checkpoint)\n",
        "    print(f\"Loading model from latest checkpoint: {model_path}\")\n",
        "else:\n",
        "    print(f\"No specific checkpoint found, loading from default output_dir: {model_path}\")\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_path,\n",
        "    num_labels=len(all_possible_labels),\n",
        "    problem_type=\"multi_label_classification\"\n",
        ")\n",
        "model.to(device) # Ensure model is on GPU\n",
        "\n",
        "# Re-initialize Trainer specifically for prediction\n",
        "# We don't need a train_dataset here\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args_for_load,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(\"\\nMaking predictions on test data...\")\n",
        "# predict returns a tuple: (predictions, label_ids, metrics)\n",
        "predictions = trainer.predict(test_dataset) # Predict using the Trainer directly with test_dataset\n",
        "logits = predictions.predictions # These are the raw logits from the model\n",
        "\n",
        "# Convert logits to probabilities using sigmoid\n",
        "test_probabilities = torch.sigmoid(torch.from_numpy(logits)).numpy()\n",
        "print(\"Predictions complete!\")\n",
        "print(f\"Shape of probabilities: {test_probabilities.shape}\")\n",
        "\n",
        "# Clean up memory after prediction (can keep these here)\n",
        "del predictions\n",
        "del trainer # Delete trainer as its job is done\n",
        "del model # Delete model after predictions are extracted\n",
        "gc.collect()\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "print(\"Memory cleaned up after prediction.\")\n",
        "\n",
        "# --- Step 7: Post-processing Predictions for Submission (MAP@3 format) ---\n",
        "# This part remains the same as before\n",
        "\n",
        "# This list will store the formatted predictions for the submission file\n",
        "submission_predictions = []\n",
        "\n",
        "print(\"\\nPost-processing predictions for submission file...\")\n",
        "\n",
        "for i in range(test_probabilities.shape[0]):\n",
        "    # Get probabilities for the current test sample\n",
        "    probs_for_sample = test_probabilities[i]\n",
        "\n",
        "    # Get the indices that would sort probabilities in descending order\n",
        "    sorted_indices = np.argsort(probs_for_sample)[::-1]\n",
        "\n",
        "    # Initialize a list for current sample's top predictions\n",
        "    current_sample_preds = []\n",
        "    num_added = 0\n",
        "    added_labels = set() # To ensure unique labels are added\n",
        "\n",
        "    for idx in sorted_indices:\n",
        "        predicted_label_str = id_to_label[idx] # Convert index back to Category:Misconception string\n",
        "\n",
        "        # Only add if we haven't reached 3 predictions and it's a unique label for this sample\n",
        "        if num_added < 3 and predicted_label_str not in added_labels:\n",
        "            current_sample_preds.append(predicted_label_str)\n",
        "            added_labels.add(predicted_label_str)\n",
        "            num_added += 1\n",
        "        elif num_added >= 3:\n",
        "            break # Stop once we have 3 predictions\n",
        "\n",
        "    # Join the predicted labels with space\n",
        "    submission_predictions.append(\" \".join(current_sample_preds))\n",
        "\n",
        "print(\"Post-processing complete.\")\n",
        "\n",
        "# --- Step 8: Generate Submission File ---\n",
        "# This part remains the same as before\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    'row_id': test_df['row_id'],\n",
        "    'Category:Misconception': submission_predictions\n",
        "})\n",
        "\n",
        "# Save the submission file\n",
        "submission_file_name = 'submission.csv'\n",
        "submission_df.to_csv(submission_file_name, index=False)\n",
        "\n",
        "print(f\"\\nSubmission file '{submission_file_name}' created successfully!\")\n",
        "print(\"First 5 rows of submission.csv:\")\n",
        "print(submission_df.head())"
      ],
      "metadata": {
        "id": "x2ODwfTOvwmj",
        "outputId": "cde7dd0f-b01b-4511-f94d-361425e4c7b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from latest checkpoint: ./results/checkpoint-6882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-1164693692.py:81: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Making predictions on test data...\n",
            "Predictions complete!\n",
            "Shape of probabilities: (3, 65)\n",
            "Memory cleaned up after prediction.\n",
            "\n",
            "Post-processing predictions for submission file...\n",
            "Post-processing complete.\n",
            "\n",
            "Submission file 'submission.csv' created successfully!\n",
            "First 5 rows of submission.csv:\n",
            "   row_id                             Category:Misconception\n",
            "0   36696  True_Correct: True_Neither: True_Misconception...\n",
            "1   36697  False_Misconception:WNB False_Misconception:In...\n",
            "2   36698  True_Neither: True_Correct: True_Misconception...\n"
          ]
        }
      ]
    }
  ]
}