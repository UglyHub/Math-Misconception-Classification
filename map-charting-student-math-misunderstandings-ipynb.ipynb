{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":104383,"databundleVersionId":12957508,"sourceType":"competition"},{"sourceId":3502519,"sourceType":"datasetVersion","datasetId":2105211},{"sourceId":4620664,"sourceType":"datasetVersion","datasetId":2663421}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-19T14:58:02.355654Z","iopub.execute_input":"2025-07-19T14:58:02.355928Z","iopub.status.idle":"2025-07-19T14:58:02.392982Z","shell.execute_reply.started":"2025-07-19T14:58:02.355904Z","shell.execute_reply":"2025-07-19T14:58:02.392315Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/debertav3small/spm.model\n/kaggle/input/debertav3small/config.json\n/kaggle/input/debertav3small/README.md\n/kaggle/input/debertav3small/tf_model.h5\n/kaggle/input/debertav3small/tokenizer_config.json\n/kaggle/input/debertav3small/pytorch_model.bin\n/kaggle/input/map-charting-student-math-misunderstandings/sample_submission.csv\n/kaggle/input/map-charting-student-math-misunderstandings/train.csv\n/kaggle/input/map-charting-student-math-misunderstandings/test.csv\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/spm.model\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/config.json\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/README (1).md\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/README.md\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/tokenizer_config (1).json\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/special_tokens_map.json\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/added_tokens.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/tokenizer.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/special_tokens_map.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/added_tokens.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/trainer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/tokenizer.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/special_tokens_map.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/added_tokens.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/run_test.sh\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/run_train.sh\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/trainer_state.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/eval_results.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/training_args.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/tokenizer.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/all_results.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/special_tokens_map.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/added_tokens.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/test_results.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/spm.model\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/config.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/trainer_state.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/training_args.bin\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/tokenizer.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/scaler.pt\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/scheduler.pt\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/special_tokens_map.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/optimizer.pt\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/rng_state.pth\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/added_tokens.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/rust_model.ot\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/tf_model.h5\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/pytorch_model.generator.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/tf_model.h5\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/generator_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/spm.model\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/config.json\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/README.md\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/tf_model.h5\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/tf_model.h5\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/tf_model.h5\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/gitattributes.txt\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# --- IMPORTANT: BEGINNING OF 0. INITIAL SETUP & CONFIGURATION CELL ---\n\n# Install necessary libraries (usually pre-installed on Kaggle)\n# !pip install -q transformers pandas scikit-learn numpy torch datasets accelerate sentencepiece\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport gc # For garbage collection\nimport os, random\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n\n# --- CRITICAL FIX HERE ---\n# Make sure to import Dataset from the 'datasets' library, not torch.utils.data\nfrom datasets import Dataset # <<< --- CHANGED THIS LINE\n# If you also need PyTorch's DataLoader, it's typically just 'from torch.utils.data import DataLoader'\n# But for Trainer, it handles DataLoaders internally, so we don't strictly need it here.\n\n\n# --- Configuration Constants ---\nMODEL_NAME = '/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/'\nMAX_LEN = 256\nBATCH_SIZE = 16\nNUM_EPOCHS = 3\nLEARNING_RATE = 5e-5\nWEIGHT_DECAY = 0.01\nSEED = 42\n\n# Set random seeds for reproducibility\nos.environ[\"PYTHONHASHSEED\"] = str(SEED)\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\n\n# Set device to GPU if available, else CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\nprint(\"Setup and Configuration Complete!\")\n\n# --- END OF 0. INITIAL SETUP & CONFIGURATION CELL ---","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:02:09.094816Z","iopub.execute_input":"2025-07-19T15:02:09.095093Z","iopub.status.idle":"2025-07-19T15:02:09.103012Z","shell.execute_reply.started":"2025-07-19T15:02:09.095073Z","shell.execute_reply":"2025-07-19T15:02:09.102422Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nSetup and Configuration Complete!\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import os, random # Added random for seeding\n\n# Define paths to competition data (Kaggle Notebooks mount data to /kaggle/input/)\nTRAIN_PATH = '/kaggle/input/map-charting-student-math-misunderstandings/train.csv'\nTEST_PATH = '/kaggle/input/map-charting-student-math-misunderstandings/test.csv'\nSAMPLE_SUBMISSION_PATH = '/kaggle/input/map-charting-student-math-misunderstandings/sample_submission.csv'\n\n# Load data\ntrain_df = pd.read_csv(TRAIN_PATH)\ntest_df = pd.read_csv(TEST_PATH)\nsample_submission_df = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n\nprint(f\"Train data shape: {train_df.shape}\")\nprint(f\"Test data shape: {test_df.shape}\") # Should be (3671, X)\nprint(f\"Sample Submission shape: {sample_submission_df.shape}\")\n\n# Fill NA values in Category and Misconception for consistency\ntrain_df.Misconception = train_df.Misconception.fillna(\"NA\")\ntrain_df[\"target\"] = train_df.Category + \":\" + train_df.Misconception\n\n# --- Calculate Correctness Feature ---\n# Identify rows where Category indicates a 'True' answer\nidx_true = train_df.Category.str.startswith(\"True\")\n\n# Count how often a specific MC_Answer is chosen when the Category is True for a given QuestionId\ncorrect_counts = (\n    train_df[idx_true]\n    .groupby([\"QuestionId\", \"MC_Answer\"])\n    .MC_Answer.agg(\"count\")\n    .reset_index(name=\"count_correct_answers\") # Renamed for clarity\n    .sort_values(\"count_correct_answers\", ascending=False)\n    .drop_duplicates([\"QuestionId\"]) # Get the top MC_Answer for each question if multiple 'True'\n)\ncorrect_counts[\"is_correct\"] = 1 # Mark these as correct choices\n\n# Merge this correctness feature into the training data\ntrain_df = train_df.merge(correct_counts[[\"QuestionId\", \"MC_Answer\", \"is_correct\"]],\n                          on=[\"QuestionId\", \"MC_Answer\"], how=\"left\")\ntrain_df.is_correct = train_df.is_correct.fillna(0).astype(int) # Fill NaNs (if MC_Answer wasn't true) with 0\n\n# Create a dictionary for quick lookup of correctness for the test set\ndict_corr = correct_counts.set_index([\"QuestionId\", \"MC_Answer\"])[\"is_correct\"].to_dict()\n\n# Apply to test data as well\ntest_df[\"is_correct\"] = test_df.apply(lambda r: int(dict_corr.get((r.QuestionId, r.MC_Answer), 0)), axis=1)\n\nprint(\"\\n--- Correctness Feature Example (Train Data) ---\")\nprint(train_df[['QuestionId', 'MC_Answer', 'Category', 'is_correct']].head())\nprint(\"\\n--- Correctness Feature Example (Test Data) ---\")\nprint(test_df[['QuestionId', 'MC_Answer', 'is_correct']].head())\n\n\n# --- Prompt Engineering Function ---\ndef build_prompt(row):\n    \"\"\"\n    Constructs the input text for the model, including the new correctness feature.\n    \"\"\"\n    correctness = \"correct.\" if row.is_correct else \"incorrect.\"\n    return (\n        f\"Question: {row.QuestionText}\\n\"\n        f\"Answer: {row.MC_Answer}\\n\"\n        f\"This answer is {correctness}\\n\" # <<< --- New context for the model\n        f\"Student Explanation: {row.StudentExplanation}\"\n    )\n\n# Apply prompt engineering to both train and test data\ntrain_df[\"text\"] = train_df.apply(build_prompt, axis=1)\ntest_df[\"text\"] = test_df.apply(build_prompt, axis=1)\n\nprint(\"\\n--- Example of New Processed Text with Correctness Feature (Train Data) ---\")\nprint(train_df['text'].iloc[0])\nprint(\"\\nData Loading and Feature Engineering Complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:02:12.480930Z","iopub.execute_input":"2025-07-19T15:02:12.481499Z","iopub.status.idle":"2025-07-19T15:02:13.390694Z","shell.execute_reply.started":"2025-07-19T15:02:12.481476Z","shell.execute_reply":"2025-07-19T15:02:13.389978Z"}},"outputs":[{"name":"stdout","text":"Train data shape: (36696, 7)\nTest data shape: (3, 5)\nSample Submission shape: (3, 2)\n\n--- Correctness Feature Example (Train Data) ---\n   QuestionId          MC_Answer      Category  is_correct\n0       31772  \\( \\frac{1}{3} \\)  True_Correct           1\n1       31772  \\( \\frac{1}{3} \\)  True_Correct           1\n2       31772  \\( \\frac{1}{3} \\)  True_Neither           1\n3       31772  \\( \\frac{1}{3} \\)  True_Neither           1\n4       31772  \\( \\frac{1}{3} \\)  True_Correct           1\n\n--- Correctness Feature Example (Test Data) ---\n   QuestionId          MC_Answer  is_correct\n0       31772  \\( \\frac{1}{3} \\)           1\n1       31772  \\( \\frac{3}{6} \\)           0\n2       32835          \\( 6.2 \\)           1\n\n--- Example of New Processed Text with Correctness Feature (Train Data) ---\nQuestion: What fraction of the shape is not shaded? Give your answer in its simplest form. [Image: A triangle split into 9 equal smaller triangles. 6 of them are shaded.]\nAnswer: \\( \\frac{1}{3} \\)\nThis answer is correct.\nStudent Explanation: 0ne third is equal to tree nineth\n\nData Loading and Feature Engineering Complete!\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"le = LabelEncoder()\ntrain_df[\"label\"] = le.fit_transform(train_df[\"target\"])\nNUM_CLASSES = len(le.classes_) # Total number of unique Category:Misconception classes\nprint(f\"Unique target classes: {NUM_CLASSES}\")\n\n# Store the classes for inverse transformation later\nid_to_label = {i: label for i, label in enumerate(le.classes_)}\n\nprint(\"Target Label Preparation Complete (using LabelEncoder)!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:02:17.620522Z","iopub.execute_input":"2025-07-19T15:02:17.620794Z","iopub.status.idle":"2025-07-19T15:02:17.634838Z","shell.execute_reply.started":"2025-07-19T15:02:17.620773Z","shell.execute_reply":"2025-07-19T15:02:17.634073Z"}},"outputs":[{"name":"stdout","text":"Unique target classes: 65\nTarget Label Preparation Complete (using LabelEncoder)!\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"print(\"Loading tokenizer…\")\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\ncollator  = DataCollatorWithPadding(tokenizer) # Data collator for padding batches\n\n# Function to tokenize a batch of texts\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n\n# Robust stratified split (handles singleton classes)\n# While a single split is shown, this setup supports full K-Fold cross-validation\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\ntrain_idx, val_idx = next(skf.split(train_df, train_df[\"label\"])) # Use train_df[\"label\"] for stratification\n\ndf_train = train_df.iloc[train_idx].reset_index(drop=True)\ndf_val   = train_df.iloc[val_idx].reset_index(drop=True)\n\n# Create Hugging Face Dataset objects\ntrain_ds = Dataset.from_pandas(df_train[[\"text\", \"label\"]]).map(tokenize, batched=True, remove_columns=[\"text\"])\nval_ds   = Dataset.from_pandas(df_val[[\"text\", \"label\"]]).map(tokenize, batched=True, remove_columns=[\"text\"])\n\n# Set format for PyTorch\ncols = [\"input_ids\", \"attention_mask\", \"label\"]\ntrain_ds.set_format(\"torch\", columns=cols)\nval_ds.set_format(\"torch\", columns=cols)\n\nprint(\"Tokenization and Dataset Creation Complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:02:20.242252Z","iopub.execute_input":"2025-07-19T15:02:20.243073Z","iopub.status.idle":"2025-07-19T15:02:30.837857Z","shell.execute_reply.started":"2025-07-19T15:02:20.243035Z","shell.execute_reply":"2025-07-19T15:02:30.836993Z"}},"outputs":[{"name":"stdout","text":"Loading tokenizer…\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/29356 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95e60f27093b4cae9463be43b4a3d6d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7340 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db925cbea7c74f588a1a4b7e4bcbb17d"}},"metadata":{}},{"name":"stdout","text":"Tokenization and Dataset Creation Complete!\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"#### **4. Model Initialization & Training**\n\n# This step initializes the model and runs the training process. The custom `map3_metric` is also defined here.\n\nprint(\"Loading model…\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=NUM_CLASSES # Number of unique classes from LabelEncoder\n).to(device)\n\nprint(f\"\\nModel loaded: {MODEL_NAME} with {NUM_CLASSES} output labels.\")\n\n\n# MAP@3 metric function from the high-scoring notebook\ndef map3_metric(eval_pred):\n    logits, labels = eval_pred\n    # Apply softmax to get probabilities for each class\n    probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n\n    # Get the top 3 predicted class indices for each sample\n    top3_preds_indices = np.argsort(-probs, axis=1)[:, :3]\n\n    # Initialize a list to store MAP@3 score for each sample\n    map_scores = []\n    for i in range(len(labels)):\n        true_label = labels[i] # The single true label for the current sample\n        current_map = 0.0\n        # Check if the true label is in the top 3 predictions\n        for rank, pred_idx in enumerate(top3_preds_indices[i]):\n            if pred_idx == true_label:\n                # Add 1/ (rank+1) if the true label is found\n                current_map = 1.0 / (rank + 1.0)\n                break # Stop as soon as the true label is found\n        map_scores.append(current_map)\n\n    return {\"map@3\": np.mean(map_scores)} # Return the mean of all samples' MAP@3 scores\n\n\n# Define Training Arguments\n# output_dir must be /kaggle/working/ for persistence in Kaggle Notebooks\nargs = TrainingArguments(\n    output_dir=\"./checkpoints\", # This will be created in /kaggle/working/\n    num_train_epochs=NUM_EPOCHS,\n    learning_rate=LEARNING_RATE,\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    load_best_model_at_end=True, # Load the best model based on metric_for_best_model\n    metric_for_best_model=\"map@3\",\n    greater_is_better=True, # Higher MAP@3 is better\n    seed=SEED,\n    report_to=\"none\",\n    save_strategy=\"epoch\", # Save every epoch\n    save_total_limit=1, # Keep only the best model\n    eval_strategy=\"epoch\", # <<< --- CORRECTED: Use 'eval_strategy' instead of 'evaluation_strategy'\n    logging_dir='./logs',\n    logging_strategy=\"steps\",\n    logging_steps=100,\n    fp16=True,\n)\n\n# Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_ds,\n    eval_dataset=val_ds, # eval_dataset is still provided for validation\n    tokenizer=tokenizer,\n    data_collator=collator,\n    compute_metrics=map3_metric, # Our custom MAP@3 metric\n)\n\n# Train the model\nprint(\"\\nStarting model training...\")\ntrainer.train()\nprint(\"Model training complete!\")\n\n# Save the final best model (or last model if load_best_model_at_end=False)\n# It will be saved inside the output_dir, i.e., /kaggle/working/checkpoints/\ntrainer.save_model(\"./best_model\")\nimport joblib; joblib.dump(le, \"./label_encoder.joblib\") # Save the LabelEncoder too\n\n# Clean up memory after training\ndel model\ndel trainer\ngc.collect()\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()\nprint(\"Memory cleaned up after training.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T15:02:37.439265Z","iopub.execute_input":"2025-07-19T15:02:37.439559Z"}},"outputs":[{"name":"stdout","text":"Loading model…\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/huggingfacedebertav3variants/deberta-v3-base/ and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nModel loaded: /kaggle/input/huggingfacedebertav3variants/deberta-v3-base/ with 65 output labels.\n\nStarting model training...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/179683207.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='201' max='2754' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 201/2754 03:29 < 44:41, 0.95 it/s, Epoch 0.22/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"import joblib # Ensure joblib is imported for loading the LabelEncoder\n\nprint(\"\\nInference on test set…\")\n\n# Load the saved best model for inference\n# The model is saved to /kaggle/working/best_model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"./best_model\", # Load from the saved path\n    num_labels=NUM_CLASSES\n).to(device)\n\n# Load the saved LabelEncoder\nle = joblib.load(\"./label_encoder.joblib\")\n\n\n# Test data preprocessing (already done in Step 1, but confirm 'text' column exists)\n# The test data's `is_correct` and `text` columns should already be populated from Step 1\n\n# Create Hugging Face Dataset for test data\ntest_ds = Dataset.from_pandas(test_df[[\"text\"]]).map(lambda b: tokenizer(b[\"text\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN), batched=True, remove_columns=[\"text\"])\ntest_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n\n# Create a DataLoader for the test set\ntest_loader = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collator) # Use collator here too\n\nmodel.eval() # Set model to evaluation mode\nall_probs = []\n\nfor batch in test_loader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad(): # Disable gradient calculation for inference\n        logits = model(**batch).logits\n    all_probs.append(torch.softmax(logits, dim=-1).cpu().numpy()) # Apply softmax and move to CPU\n\nprobs = np.vstack(all_probs) # Stack all probabilities into a single NumPy array\n\nprint(\"Inference complete!\")\nprint(f\"Shape of probabilities: {probs.shape}\")\n\n# Clean up memory after inference\ndel model\ndel test_loader\ndel test_ds\ngc.collect()\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()\nprint(\"Memory cleaned up after inference.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get top-3 predictions for each row\ntop3_indices = np.argsort(-probs, axis=1)[:, :3]\n\n# Convert indices back to original Category:Misconception labels\nlabels_flat = le.inverse_transform(top3_indices.flatten()).reshape(top3_indices.shape)\n\n# Join the top-3 predicted labels with space\njoined_predictions = [\" \".join(row) for row in labels_flat]\n\n# Create the submission DataFrame\nsubmission_df = pd.DataFrame({\n    \"row_id\": test_df.row_id, # Use original row_id from test_df\n    \"Category:Misconception\": joined_predictions\n})\n\n# Save the submission file to the Kaggle working directory\nsubmission_file_name = \"submission.csv\"\nsubmission_df.to_csv(f\"/kaggle/working/{submission_file_name}\", index=False)\n\nprint(f\"Saved {submission_file_name} ✅\")\nprint(\"\\nFirst 5 rows of submission.csv:\")\nprint(submission_df.head())\nprint(f\"\\nTotal rows in submission.csv: {len(submission_df)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}